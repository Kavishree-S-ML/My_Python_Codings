<source>
	pos_file /var/log/td-agent/syslog.pos
	path /var/log/syslog, /var/log/auth.log, /var/log/messages, /var/log/secure
	tag linux-syslog.*
	@type tail
	<parse>
		@type none
	</parse>
</source>

<match linux-syslog.**>
	@type rewrite_tag_filter
	<rule>
		key message
		pattern (?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>(python)|(collectd))
		tag clear
	</rule>
	<rule>
		key message
		pattern (?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>.*)
		tag process.extra_data
	</rule>
</match>

<filter process.extra_data>
	@type parser
	key_name message
	<parse>
		expression (?<time>[^ ]*\s*[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[^ :\[]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? (?<message>.*)
		@type regexp
	</parse>
</filter>

<filter process.*>
	enable_ruby
	@type record_transformer
	<record>
		node "#{Socket.gethostname}"
		_plugin "linux"
		ident "${record['ident']}"
		_documentType "syslog"
		level "${n_level='info'; if record.key?('level') == nil or record['level'] == nil then n_level else record['level'] end}"
		pid "${record['pid']}"
		host "${record['host']}"
		file "${tag_suffix[1]}"
		time "${require 'time'; time.to_time.to_i}"
	</record>
</filter>

<match process.*>
	index_name fluentd
	host 10.11.100.45
	@type elasticsearch
	port 9200
	name default-es
	type_name _doc
	flush_interval 30s
</match>

<match clear>
	@type null
</match>